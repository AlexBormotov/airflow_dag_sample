# airflow_dag_sample
Test task for great job opportunity

Даг для AirFlow обращается к API и перебрасывает данные в гиппотетическую базу Postgres (можно подключить любую через ".env"). Можно было бы настроить переменные через Add conection в интерфейсе AirFlow или записать в переменные X-COM, но я не разворачивал сам AirFlow у себя, и через .env мне как-то более удобно, когда файл с настройками под рукой.

На всякий случай я добавил второй вид подключения - через PostgresHook, часто в компаниях есть настроенные хуки, это ускоряет работу и повышает конфиденциальность данных.

Даг реализован максимально просто с использованием pandas, в случае если критически важно ускорить выполнение можно обойти использование pandas, я бы попробовал записывать значения ключей в таблицу построчно или формаровал микро-батчи для записи, тогда бы мне пригодилась дополнительная таблица, которая хранила бы индекс последней записанной строки (это только один из способов, не факт, что самый лучший, но я его использовал на практике)

Комеентарии в даги реализованы на английском - так более профессионально

P.S. если помимо этого требуются DDL-скрипты, или подразумевалась обязательная запись через запуск "INSERT INTO ..." - только скажите, всё реализуемо. Я просто шёл по пути наименьшего сопротивления)
